{
	// Place your snippets for python here. Each snippet is defined under a snippet name and has a prefix, body and 
	// description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are:
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. Placeholders with the 
	// same ids are connected.
	// Example:
	// "Print to console": {
	// 	"prefix": "log",
	// 	"body": [
	// 		"console.log('$1');",
	// 		"$2"
	// 	],
	// 	"description": "Log output to console"
	// }
	"args": {
		"prefix": "jupyter",
		"body": [
			"def get_args():",
			"    parser = argparse.ArgumentParser()",
			"    parser.add_argument(\"-\", \"--\", default, type=)",
			"    return parser.parse_args()",
			"",
			"if '--transport=\"tcp\"' in sys.argv: # vscode jupyter",
			"    parser = argparse.ArgumentParser()",
			"    args = parser.parse_args(args=[])",
			"    args. = ",
			"else:",
			"    args = get_args()"
		],
		"description": ""
	},
	"fix_seed": {
		"prefix": "fix_seed",
		"body": [
			"def fix_seed(seed):",
			"    # random",
			"    random.seed(seed)",
			"    # Numpy",
			"    np.random.seed(seed)",
			"    # Pytorch",
			"    torch.manual_seed(seed)",
			"    torch.cuda.manual_seed_all(seed)",
			"    torch.backends.cudnn.deterministic = True",
			"",
			"SEED = 42",
			"fix_seed(SEED)",
		],
		"description": ""
	},
	"import_ml_library": {
		"prefix": "import_ml_library",
		"body": [
			"import os",
			"import sys",
			"import random",
			"import argparse",
			"from pathlib import Path",
			"from typing import List",
			"",
			"import torch",
			"import torch.nn as nn",
			"import torch.optim as optim",
			"import torch.nn.functional as F",
			"import numpy as np",
			"import matplotlib.pyplot as plt",
			"from tqdm import tqdm",
			"from torch.utils.tensorboard import SummaryWriter",
			"",
			"writer = SummaryWriter(\"runs/experiment1\")",
			"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
			"",
			"def worker_init_fn(worker_id):",
			"    np.random.seed(np.random.get_state()[1][0] + worker_id)",
		],
		"description": ""
	},
	"create_custom_dataset": {
		"prefix": "create_custom_dataset",
		"body": [
			"class Mydataset(torch.utils.data.Dataset):",
			"    def __init__(self, X, y):",
			"        self.X = X",
			"        self.y = y",
			"",
			"    def __len__(self):",
			"        return len(self.X)",
			"",
			"    def __getitem__(self, index):",
			"        feature = self.X[index]",
			"        label = self.y[index]",
			"        # 前処理などを書く -----",
			"",
			"        # --------------------",
			"        return feature, label",
			"",
			"train_dataset = Mydataset(train_X, train_y)",
			"test_dataset = Mydataset(test_X, test_y)",
			"",
			"train_loader = torch.utils.data.DataLoader(train_dataset,",
			"                                           batch_size=16,",
			"                                           shuffle=True,",
			"                                           num_workers=2,",
			"                                           pin_memory=True,",
			"                                           worker_init_fn=worker_init_fn",
			"                                           )",
			"test_loader = torch.utils.data.DataLoader(test_dataset,",
			"                                          batch_size=16,",
			"                                          shuffle=False,",
			"                                          num_workers=2,",
			"                                          pin_memory=True,",
			"                                          worker_init_fn=worker_init_fn",
			"                                          )",
			"",
		],
		"description": ""
	},
	"create_model": {
		"prefix": "model_template",
		"body": [
			"class Model(nn.Module):",
			"    def __init__(self):",
			"        super().__init__()",
			"",
			"    def forward(self, x):",
			"        return ",
		],
		"description": ""
	},
	"train_model": {
		"prefix": "train_model",
		"body": [
			"criterion = nn.",
			"",
			"def _train(args, train_loader, dev_loader):",
			"    best_dev_score = -1",
			"",
			"    model = Model()",
			"    if args.init_model is not None:",
			"        model.load_state_dict(torch.load(args.init_model))",
			"    model = model.to(args.device)",
			"    optimizer = optim.Adam(model.parameters(), lr=args.lr)",
			"",
			"    for epoch in tqdm(range(1, args.epochs + 1)):",
			"        model.train()",
			"        train_batch_loss = []",
			"        output_list = []",
			"        for data, label in train_loader:",
			"            data, label = data.to(args.device), label.to(args.device)",
			"            optimizer.zero_grad()",
			"            output = model(data)",
			"            loss = criterion(output, label)",
			"            loss.backward()",
			"            optimizer.step()",
			"            train_batch_loss.append(loss.item())",
			"            output_list.append(output.detach().cpu().numpy())",
			"",
			"        model.eval()",
			"        dev_batch_loss = []",
			"        with torch.no_grad():",
			"            for data, label in dev_loader:",
			"                data, label = data.to(args.device), label.to(args.device)",
			"                output = model(data)",
			"                loss = criterion(output, label)",
			"                dev_batch_loss.append(loss.item())",
			"",
			"        if best_dev_score < dev_score:",
			"            best_dev_score = dev_score",
			"            early_stopping_round = 0",
			"            if args.save:",
			"                torch.save(",
			"                        model.state_dict(),",
			"                        os.path.join(args.save_dir / \".pt\"),",
			"                )",
			"                print(\"save:{}\".format(args.save_dir / \".pt\"))",
			"        else:",
			"            early_stopping_round += 1",
			"",
			"        if early_stopping_round > args.early_stopping:",
			"            print(\"Early Stopping ...\")",
			"            break",
			"        yield dev_score",
		],
		"description": ""
	},
	"evaluate_model": {
		"prefix": "evaluate_model",
		"body": [
			"def evaluate(args, eval_loader):",
			"    model = Model()",
			"    if init_model is not None:",
			"        model.load_state_dict(torch.load(init_model))",
			"    model = model.to(config.device)",
			"",
			"    model.eval()",
			"    eval_batch_loss = []",
			"    with torch.no_grad():",
			"        for data, label in eval_loader:",
			"            data, label = data.to(device), label.to(device)",
			"            output = model(data)",
			"            loss = criterion(output, label)",
			"            eval_batch_loss.append(loss.item())",
			"",
			"    return eval_batch_loss",
		],
		"description": ""
	},
	"run_optuna": {
		"prefix": "run_optuna",
		"body": [
			"if mode == \"tuning\":",
			"    def objective(trial):",
			"        args.lr = trial.suggest_loguniform(\"other_lr\", 1e-5, 1e-3)",
			"        args.dropout_rate = trial.suggest_loguniform(\"dropout\", 0.1, 1.0)",
			"",
			"        best_score = -1",
			"        for step, score in enumerate(_train(args, train_loader, dev_loader)):",
			"            best_score = max(best_score, score)",
			"            trial.report(score, step)",
			"            if trial.should_prune():",
			"                raise optuna.TrialPruned()",
			"        return best_score",
			"",
			"    pruner = optuna.pruners.SuccessiveHalvingPruner()",
			"    study = optuna.create_study(",
			"        direction=\"maximize\",",
			"        pruner=pruner,",
			"    )",
			"    study.optimize(objective, n_trials=args.optuna_n_trials)",
			"    print(f\"best dev accuracy: {study.best_value}\")",
			"    print(f\"best parameter: {study.best_params}\")",
			"elif mode == \"learning\":",
			"    dev_score_list = train(args, train_loader, dev_loader)",
			"elif mode == \"eval\":",
			"    eval_batch_loss = evaluate(args, eval_loader)",
		],
		"description": ""
	},
	"cal_score": {
		"prefix": "cal_score",
		"body": [
			"def cal_score(output_list, label_list):",
			"    np_output = torch.cat(output_list).numpy()",
			"    np_output = np.where(np_output < 0.5, 0, 1)",
			"    np_label = torch.cat(label_list).numpy()",
			"    acc = sum(np_output == np_label) / len(np_label)",
			"    tp = sum((np_output == np_label) & (np_label == 1))",
			"    # tn = sum((np_output == np_label) & (np_label == 0))",
			"    fp = sum((np_output == 1) & (np_label == 0))",
			"    fn = sum((np_output == 0) & (np_label == 1))",
			"    p = tp / (tp + fp + 1e-10)",
			"    r = tp / (tp + fn + 1e-10)",
			"    f = 2 * r * p / (r + p + 1e-10)",
			"    return acc, p, r, f",
		],
		"description": ""
	},
}

